{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "V2_XGB_Deployment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO6vjwbuYfRGGaeF230mSoL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhileswar-Komati/Suicide_Ideation/blob/master/S_VS_T_XGB_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTlu-l_bdI1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081bbc0d-cdd0-451a-ebf5-fd0993bb75a0"
      },
      "source": [
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py\n",
        "!pip install sentencepiece\n",
        "!pip install bert-for-tf2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 4.3MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n",
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/a1/acb891630749c56901e770a34d6bac8a509a367dd74a05daf7306952e910/bert-for-tf2-0.14.9.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.4MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/e0/4f663d8abf83c8084b75b995bd2ab3a9512ebc5b97206fde38cef906ab07/py-params-0.10.2.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-cp37-none-any.whl size=30535 sha256=1776b3404539fdb3afe5b7afa66bb0e2cfe36e981c7816804fb77e0bf47794b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/04/ee/347bd9f5b821b637c76411d280271a857aece00358896a230f\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-cp37-none-any.whl size=7912 sha256=69138135989ea2c2977a484b827f6732668978b9f354878e70fc52e62e89bdcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/4a/70/ff12450229ff1955abf01f365051d4faae1c20aef53ab4cf09\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp37-none-any.whl size=19472 sha256=e7bdcae2fa0e0d478afa5eca74675119d99ee6367cb869eaf8b67d604f55561a\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2DwSquv8qSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3622aa9-c9c9-4f25-e19d-c4c5c93acb70"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import os, re\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH98Qwfo8LMj",
        "outputId": "11888d82-7dd2-49c7-9a96-0b22f9f432af"
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"nikhileswarkomati\"\n",
        "os.environ['KAGGLE_KEY'] = \"001b3a30170775e55950edb6ff0c9b17\"\n",
        "!kaggle datasets download -d nikhileswarkomati/suicide-watch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading suicide-watch.zip to /content\n",
            " 84% 97.0M/115M [00:01<00:00, 61.3MB/s]\n",
            "100% 115M/115M [00:01<00:00, 85.3MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AXemEX88XIu",
        "outputId": "8fe624bc-e1e8-447f-f7da-f16ca4093a6c"
      },
      "source": [
        "!unzip '/content/suicide-watch.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/suicide-watch.zip\n",
            "  inflating: SuicideAndDepression_Detection.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "WqC-R1QJ8gKD",
        "outputId": "7b95c1ea-dc19-422a-9bb9-c3476f9b593b"
      },
      "source": [
        "data = pd.read_csv('/content/SuicideAndDepression_Detection.csv', lineterminator = '\\n')\n",
        "data.sample(5)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>210166</th>\n",
              "      <td>Open letter to Minecraft Dear Minecraft,\\n\\nI ...</td>\n",
              "      <td>teenagers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78018</th>\n",
              "      <td>Done.I am so tired of waking up, i wake up in ...</td>\n",
              "      <td>SuicideWatch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291067</th>\n",
              "      <td>No prospects, bleak future. Dead End. 21 years...</td>\n",
              "      <td>SuicideWatch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119428</th>\n",
              "      <td>Let's draw together https://r7.whiteboardfox.c...</td>\n",
              "      <td>teenagers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171558</th>\n",
              "      <td>I just turned 15 today. Is there any advice th...</td>\n",
              "      <td>teenagers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text         class\n",
              "210166  Open letter to Minecraft Dear Minecraft,\\n\\nI ...     teenagers\n",
              "78018   Done.I am so tired of waking up, i wake up in ...  SuicideWatch\n",
              "291067  No prospects, bleak future. Dead End. 21 years...  SuicideWatch\n",
              "119428  Let's draw together https://r7.whiteboardfox.c...     teenagers\n",
              "171558  I just turned 15 today. Is there any advice th...     teenagers"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4_3TFUs8uA-",
        "outputId": "e4e1924f-a259-42c7-bd7d-aa445be2508b"
      },
      "source": [
        "print(data.shape)\n",
        "data['class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(348111, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "teenagers       116037\n",
              "SuicideWatch    116037\n",
              "depression      116037\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lRhkGN8IE-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ba6d49-e4ee-4983-b771-d2acf1abd80c"
      },
      "source": [
        "def preprocess(string):\n",
        "    phrase = str(string)\n",
        "    phrase = re.sub('[^a-z]+', ' ', phrase, flags = re.IGNORECASE)\n",
        "    phrase = re.sub('(\\s+)', ' ', phrase)\n",
        "    phrase = re.sub('http\\S+', ' ', phrase)\n",
        "    phrase = phrase.lower()\n",
        "    words_li = ['filler']\n",
        "    li = list(stopwords.words()) + words_li\n",
        "    text_tokens = word_tokenize(phrase)\n",
        "    return \" \".join([word for word in text_tokens if word not in li])\n",
        "print(data['text'].apply(lambda x: len(x.split(' '))).sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59527144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKPzRpE5JzQQ"
      },
      "source": [
        "data['text'] = data['text'].map(lambda string: preprocess(string))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaDIwATpsLRU",
        "outputId": "aa5cb450-58b1-49e2-cf14-52ecfb3020fd"
      },
      "source": [
        "print(data['text'].apply(lambda x: len(x.split(' '))).sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59527144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVEHdqxP671Q",
        "outputId": "a12cd66e-0c72-4424-8d2a-4dfbc89bb336"
      },
      "source": [
        "data.loc[(data['class'] != 'depression'), 'text'][:1000].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txfNhIm4-LEK",
        "outputId": "75f99442-a4dd-44d6-cf3b-3272bd614066"
      },
      "source": [
        "# X = data.iloc[:, 0].values\n",
        "# y = data.iloc[:, 1].values\n",
        "\n",
        "# le = LabelEncoder()\n",
        "\n",
        "# y = le.fit_transform(y)\n",
        "\n",
        "# train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = 0.5, stratify = y)\n",
        "# train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, train_size = 0.2, stratify = train_y)\n",
        "# print(train_X.shape, test_y.shape, val_X.shape)\n",
        "\n",
        "#------------------------------------------------------------------------------------------\n",
        "X = data.loc[(data['class'] != 'depression'), 'text'].values\n",
        "y = data.loc[(data['class'] != 'depression'), 'class'].values\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = 0.5, stratify = y)\n",
        "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, train_size = 0.2, stratify = train_y)\n",
        "print(train_X.shape, test_y.shape, val_X.shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23207,) (116037,) (92830,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk1UEAHi8mHd"
      },
      "source": [
        "[preproele for ele in data.loc[(data['class'] != 'depression'), 'text'][:10000].values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4zppob4oOwy"
      },
      "source": [
        "embeddings = embed(data.loc[(data['class'] != 'depression'), 'text'][:10000].values)\n",
        "train_y = le.fit_transform(data.loc[(data['class'] != 'depression'), 'class'][:10000].values)\n",
        "test_embeddings = embed(data.loc[(data['class'] != 'depression'), 'text'][10000:15000].values)\n",
        "test_y = le.transform(data.loc[(data['class'] != 'depression'), 'class'][10000:15000].values)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------------\n",
        "# embeddings = embed([preprocess(ele) for ele in data.loc[(data['class'] != 'depression'), 'text'][:10000].values])\n",
        "# train_y = le.fit_transform(data.loc[(data['class'] != 'depression'), 'class'][:10000].values)\n",
        "# test_embeddings = embed([preprocess(ele) for ele in data.loc[(data['class'] != 'depression'), 'text'][10000:15000].values])\n",
        "# test_y = le.transform(data.loc[(data['class'] != 'depression'), 'class'][10000:15000].values)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tk3Vx-avQm2",
        "outputId": "876bf907-86fe-4225-a7e4-d9ee95e3b4cb"
      },
      "source": [
        "xgb1 = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', XGBClassifier()),\n",
        "              ])\n",
        "\n",
        "xgb1.fit(train_X, train_y)\n",
        "y_pred = xgb1.predict(test_X)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, test_y))\n",
        "print(classification_report(test_y, y_pred))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.8852176460956419\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.85      0.88     58019\n",
            "           1       0.86      0.92      0.89     58018\n",
            "\n",
            "    accuracy                           0.89    116037\n",
            "   macro avg       0.89      0.89      0.89    116037\n",
            "weighted avg       0.89      0.89      0.89    116037\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbRXcqp_H90R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9fb55c8-c7e5-447c-dbbb-88c05c1e5aa3"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd2 = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', SGDClassifier()),\n",
        "              ])\n",
        "\n",
        "sgd2.fit(train_X, train_y)\n",
        "y_pred = sgd2.predict(test_X)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, test_y))\n",
        "print(classification_report(test_y, y_pred))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.9277385661470048\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93     58019\n",
            "           1       0.92      0.94      0.93     58018\n",
            "\n",
            "    accuracy                           0.93    116037\n",
            "   macro avg       0.93      0.93      0.93    116037\n",
            "weighted avg       0.93      0.93      0.93    116037\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}