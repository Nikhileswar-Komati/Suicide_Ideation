{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S_VS_T_USE_LSTM_LSTM-CNN",
      "provenance": [],
      "authorship_tag": "ABX9TyPkQ9BQMvDPgStWsEDCPR9c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhileswar-Komati/Suicide_Ideation/blob/master/S_VS_T_USE_LSTM_LSTM_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2DwSquv8qSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18de1d30-2602-4c3f-e15b-3877ec40ca31"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import os, re\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH98Qwfo8LMj",
        "outputId": "7f0fed57-5656-4a79-d2ea-f83a2d43816b"
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"nikhileswarkomati\"\n",
        "os.environ['KAGGLE_KEY'] = \"001b3a30170775e55950edb6ff0c9b17\"\n",
        "!kaggle datasets download -d nikhileswarkomati/suicide-watch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading suicide-watch.zip to /content\n",
            "100% 115M/115M [00:01<00:00, 131MB/s] \n",
            "100% 115M/115M [00:01<00:00, 106MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AXemEX88XIu",
        "outputId": "df937cbd-0b23-4a10-b982-fe7e561d9ce3"
      },
      "source": [
        "!unzip '/content/suicide-watch.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/suicide-watch.zip\n",
            "  inflating: SuicideAndDepression_Detection.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "WqC-R1QJ8gKD",
        "outputId": "246f3ba5-b2c8-4305-e6e5-eab4096cd06a"
      },
      "source": [
        "data = pd.read_csv('/content/SuicideAndDepression_Detection.csv', lineterminator = '\\n')\n",
        "data.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>242456</th>\n",
              "      <td>I'm scared.It's not fair. Everyone expects me ...</td>\n",
              "      <td>depression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274632</th>\n",
              "      <td>I woke up from my \"overdose\"Maybe i'll just ad...</td>\n",
              "      <td>SuicideWatch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147145</th>\n",
              "      <td>I’m gonna wreck my shit right here and now Bac...</td>\n",
              "      <td>teenagers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284000</th>\n",
              "      <td>This hurtsI'm tired, but I have to be alert al...</td>\n",
              "      <td>depression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199500</th>\n",
              "      <td>In this fake scenario, one has to die. Your mo...</td>\n",
              "      <td>teenagers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text         class\n",
              "242456  I'm scared.It's not fair. Everyone expects me ...    depression\n",
              "274632  I woke up from my \"overdose\"Maybe i'll just ad...  SuicideWatch\n",
              "147145  I’m gonna wreck my shit right here and now Bac...     teenagers\n",
              "284000  This hurtsI'm tired, but I have to be alert al...    depression\n",
              "199500  In this fake scenario, one has to die. Your mo...     teenagers"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4_3TFUs8uA-",
        "outputId": "6c64d862-4296-454d-d405-7bced8d53972"
      },
      "source": [
        "print(data.shape)\n",
        "data['class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(348111, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "depression      116037\n",
              "SuicideWatch    116037\n",
              "teenagers       116037\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txfNhIm4-LEK",
        "outputId": "174ca594-d0bd-427d-804a-2d7337c897c4"
      },
      "source": [
        "# X = data.iloc[:, 0].values\n",
        "# y = data.iloc[:, 1].values\n",
        "\n",
        "# le = LabelEncoder()\n",
        "\n",
        "# y = le.fit_transform(y)\n",
        "\n",
        "# train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = 0.5, stratify = y)\n",
        "# train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, train_size = 0.2, stratify = train_y)\n",
        "# print(train_X.shape, test_y.shape, val_X.shape)\n",
        "\n",
        "#------------------------------------------------------------------------------------------\n",
        "X = data.loc[(data['class'] != 'depression'), 'text'].values\n",
        "y = data.loc[(data['class'] != 'depression'), 'class'].values\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = 0.5, stratify = y)\n",
        "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, train_size = 0.2, stratify = train_y)\n",
        "print(train_X.shape, test_y.shape, val_X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23207,) (116037,) (92830,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4zppob4oOwy"
      },
      "source": [
        "embeddings = embed(data.loc[(data['class'] != 'depression'), 'text'][:10000].values)\n",
        "train_y = le.fit_transform(data.loc[(data['class'] != 'depression'), 'class'][:10000].values)\n",
        "test_embeddings = embed(data.loc[(data['class'] != 'depression'), 'text'][10000:15000].values)\n",
        "test_y = le.transform(data.loc[(data['class'] != 'depression'), 'class'][10000:15000].values)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------------\n",
        "# embeddings = embed([preprocess(ele) for ele in data.loc[(data['class'] != 'depression'), 'text'][:10000].values])\n",
        "# train_y = le.fit_transform(data.loc[(data['class'] != 'depression'), 'class'][:10000].values)\n",
        "# test_embeddings = embed([preprocess(ele) for ele in data.loc[(data['class'] != 'depression'), 'text'][10000:15000].values])\n",
        "# test_y = le.transform(data.loc[(data['class'] != 'depression'), 'class'][10000:15000].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqqdTqmL7MiQ",
        "outputId": "fd61172d-1d36-4f7c-cd14-0a19596f916d"
      },
      "source": [
        "embeddings.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10000, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FJ8EWELvvCq",
        "outputId": "82a40e7a-7b39-4fd9-b801-fc62cb2d5dde"
      },
      "source": [
        "from keras.layers import LSTM, Conv1D, MaxPooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import itertools\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Embedding\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import utils\n",
        "X_train = embeddings\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "\n",
        "model = Sequential()\n",
        "# model.add(LSTM(100, dropout = 0.2, recurrent_dropout = 0.2, input_shape = (X_train.shape[1], 1)))\n",
        "# model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape = (512, 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(100, dropout = 0.1, recurrent_dropout = 0.1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "print(model.summary())\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('model_lstm.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
        "callbacks_list = [checkpoint, earlystopping]\n",
        "model.fit(X_train, train_y, epochs=20, batch_size = 32,verbose = 1, callbacks = callbacks_list, validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_2 (Conv1D)            (None, 512, 32)           128       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 256, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 53,429\n",
            "Trainable params: 53,429\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "282/282 [==============================] - 135s 470ms/step - loss: 0.6168 - accuracy: 0.6673 - val_loss: 0.4287 - val_accuracy: 0.8110\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.81100, saving model to model_lstm.h5\n",
            "Epoch 2/20\n",
            "282/282 [==============================] - 135s 479ms/step - loss: 0.4357 - accuracy: 0.8100 - val_loss: 0.4022 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.81100 to 0.83000, saving model to model_lstm.h5\n",
            "Epoch 3/20\n",
            "282/282 [==============================] - 139s 489ms/step - loss: 0.4230 - accuracy: 0.8157 - val_loss: 0.4158 - val_accuracy: 0.8170\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.83000\n",
            "Epoch 4/20\n",
            "282/282 [==============================] - 132s 468ms/step - loss: 0.4324 - accuracy: 0.8110 - val_loss: 0.4363 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.83000\n",
            "Epoch 5/20\n",
            "282/282 [==============================] - 133s 472ms/step - loss: 0.4272 - accuracy: 0.8116 - val_loss: 0.4036 - val_accuracy: 0.8320\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.83000 to 0.83200, saving model to model_lstm.h5\n",
            "Epoch 6/20\n",
            "282/282 [==============================] - 134s 476ms/step - loss: 0.4075 - accuracy: 0.8194 - val_loss: 0.3876 - val_accuracy: 0.8290\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.83200\n",
            "Epoch 7/20\n",
            "282/282 [==============================] - 140s 497ms/step - loss: 0.3990 - accuracy: 0.8264 - val_loss: 0.3754 - val_accuracy: 0.8450\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.83200 to 0.84500, saving model to model_lstm.h5\n",
            "Epoch 8/20\n",
            "282/282 [==============================] - 134s 475ms/step - loss: 0.3907 - accuracy: 0.8315 - val_loss: 0.3753 - val_accuracy: 0.8400\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.84500\n",
            "Epoch 9/20\n",
            "282/282 [==============================] - 133s 473ms/step - loss: 0.3813 - accuracy: 0.8344 - val_loss: 0.3683 - val_accuracy: 0.8450\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.84500\n",
            "Epoch 10/20\n",
            "282/282 [==============================] - 133s 472ms/step - loss: 0.3712 - accuracy: 0.8372 - val_loss: 0.3822 - val_accuracy: 0.8440\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.84500\n",
            "Epoch 11/20\n",
            "282/282 [==============================] - 133s 473ms/step - loss: 0.3687 - accuracy: 0.8433 - val_loss: 0.3712 - val_accuracy: 0.8450\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.84500\n",
            "Epoch 12/20\n",
            "282/282 [==============================] - 140s 497ms/step - loss: 0.3823 - accuracy: 0.8389 - val_loss: 0.3636 - val_accuracy: 0.8440\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.84500\n",
            "Epoch 00012: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8f5f20e950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oPJHxBkzEvn",
        "outputId": "8dbfb7df-9db0-4fda-8dff-cd32cc6c3625"
      },
      "source": [
        "X_test = test_embeddings\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/model_lstm.h5')\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.rint(y_pred)\n",
        "y_test = test_y\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8318\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.86      0.82      2293\n",
            "         1.0       0.88      0.80      0.84      2707\n",
            "\n",
            "    accuracy                           0.83      5000\n",
            "   macro avg       0.83      0.83      0.83      5000\n",
            "weighted avg       0.84      0.83      0.83      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRImcaIKDfWE",
        "outputId": "ec3bf62d-5ea7-4edd-dfc7-57557e91e1d7"
      },
      "source": [
        "from keras.layers import LSTM, Conv1D, MaxPooling1D\n",
        "from keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import itertools\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Embedding\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import utils\n",
        "X_train = embeddings\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, dropout = 0.2, recurrent_dropout = 0.2, input_shape = (512, 1)))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "print(model.summary())\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
        "callbacks_\n",
        "list = [checkpoint, earlystopping]\n",
        "model.fit(X_train, train_y, epochs=20, batch_size = 32,verbose = 1, callbacks = callbacks_list, validation_split = 0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_7 (LSTM)                (None, 100)               40800     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 40,901\n",
            "Trainable params: 40,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "282/282 [==============================] - 219s 765ms/step - loss: 0.6776 - accuracy: 0.5844 - val_loss: 0.6326 - val_accuracy: 0.7240\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.72400, saving model to model.h5\n",
            "Epoch 2/20\n",
            "282/282 [==============================] - 220s 779ms/step - loss: 0.5800 - accuracy: 0.7392 - val_loss: 0.4757 - val_accuracy: 0.8030\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.72400 to 0.80300, saving model to model.h5\n",
            "Epoch 3/20\n",
            "282/282 [==============================] - 223s 791ms/step - loss: 0.5098 - accuracy: 0.7603 - val_loss: 0.4807 - val_accuracy: 0.8080\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.80300 to 0.80800, saving model to model.h5\n",
            "Epoch 4/20\n",
            "282/282 [==============================] - 222s 788ms/step - loss: 0.4979 - accuracy: 0.7664 - val_loss: 0.4483 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.80800\n",
            "Epoch 5/20\n",
            "282/282 [==============================] - 222s 788ms/step - loss: 0.4939 - accuracy: 0.7679 - val_loss: 0.4789 - val_accuracy: 0.7770\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.80800\n",
            "Epoch 6/20\n",
            "282/282 [==============================] - 222s 787ms/step - loss: 0.4986 - accuracy: 0.7687 - val_loss: 0.4272 - val_accuracy: 0.8150\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.80800 to 0.81500, saving model to model.h5\n",
            "Epoch 7/20\n",
            "282/282 [==============================] - 223s 791ms/step - loss: 0.4756 - accuracy: 0.7803 - val_loss: 0.4331 - val_accuracy: 0.8090\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.81500\n",
            "Epoch 8/20\n",
            "282/282 [==============================] - 222s 787ms/step - loss: 0.4721 - accuracy: 0.7821 - val_loss: 0.4220 - val_accuracy: 0.8140\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.81500\n",
            "Epoch 9/20\n",
            "282/282 [==============================] - 223s 790ms/step - loss: 0.4835 - accuracy: 0.7709 - val_loss: 0.4658 - val_accuracy: 0.7870\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.81500\n",
            "Epoch 10/20\n",
            "282/282 [==============================] - 223s 790ms/step - loss: 0.4886 - accuracy: 0.7723 - val_loss: 0.4325 - val_accuracy: 0.8150\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.81500\n",
            "Epoch 11/20\n",
            "282/282 [==============================] - 223s 792ms/step - loss: 0.4770 - accuracy: 0.7749 - val_loss: 0.4199 - val_accuracy: 0.8210\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.81500 to 0.82100, saving model to model.h5\n",
            "Epoch 12/20\n",
            "282/282 [==============================] - 222s 789ms/step - loss: 0.4812 - accuracy: 0.7796 - val_loss: 0.4254 - val_accuracy: 0.8160\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.82100\n",
            "Epoch 13/20\n",
            "282/282 [==============================] - 223s 790ms/step - loss: 0.4612 - accuracy: 0.7868 - val_loss: 0.4365 - val_accuracy: 0.8120\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.82100\n",
            "Epoch 14/20\n",
            "282/282 [==============================] - 224s 793ms/step - loss: 0.4673 - accuracy: 0.7803 - val_loss: 0.4409 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.82100\n",
            "Epoch 15/20\n",
            "282/282 [==============================] - 223s 790ms/step - loss: 0.4685 - accuracy: 0.7871 - val_loss: 0.3919 - val_accuracy: 0.8270\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.82100 to 0.82700, saving model to model.h5\n",
            "Epoch 16/20\n",
            "282/282 [==============================] - 229s 812ms/step - loss: 0.7098 - accuracy: 0.6262 - val_loss: 0.5430 - val_accuracy: 0.7450\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.82700\n",
            "Epoch 17/20\n",
            "282/282 [==============================] - 228s 809ms/step - loss: 0.5730 - accuracy: 0.7184 - val_loss: 0.5816 - val_accuracy: 0.6940\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.82700\n",
            "Epoch 18/20\n",
            "282/282 [==============================] - 228s 810ms/step - loss: 0.6022 - accuracy: 0.6702 - val_loss: 0.5749 - val_accuracy: 0.7420\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.82700\n",
            "Epoch 19/20\n",
            "282/282 [==============================] - 230s 817ms/step - loss: 0.5831 - accuracy: 0.6975 - val_loss: 0.5088 - val_accuracy: 0.7870\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.82700\n",
            "Epoch 20/20\n",
            "282/282 [==============================] - 228s 810ms/step - loss: 0.5081 - accuracy: 0.7600 - val_loss: 0.4680 - val_accuracy: 0.7950\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.82700\n",
            "Epoch 00020: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8f5cdea550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw_EfP-JFhLC",
        "outputId": "27ac9056-f07a-40e1-de32-50e86d78d322"
      },
      "source": [
        "X_test = test_embeddings\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/model.h5')\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.rint(y_pred)\n",
        "y_test = test_y\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.815\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.84      0.80      0.82      2613\n",
            "         1.0       0.79      0.83      0.81      2387\n",
            "\n",
            "    accuracy                           0.81      5000\n",
            "   macro avg       0.81      0.82      0.81      5000\n",
            "weighted avg       0.82      0.81      0.82      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aThY_EqIfKTK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}