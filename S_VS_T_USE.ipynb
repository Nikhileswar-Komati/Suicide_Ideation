{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_USE_TRAIN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMXBByi76S7TDM4JCvVG7PV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhileswar-Komati/Suicide_Ideation/blob/master/S_VS_T_USE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ob28RUGZ9uV"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.4.5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHJrHzr8aF0m",
        "outputId": "b6ab3355-b904-48b0-b770-047683c8a6d6"
      },
      "source": [
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version: \", sparknlp.version())\n",
        "print(\"Apache Spark version\", spark.version)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version:  2.4.5\n",
            "Apache Spark version 2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeibSRgYadTI",
        "outputId": "a2b5f7d8-9bab-40de-d297-516d415b747d"
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"nikhileswarkomati\"\n",
        "os.environ['KAGGLE_KEY'] = \"001b3a30170775e55950edb6ff0c9b17\"\n",
        "!kaggle datasets download -d nikhileswarkomati/suicide-watch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading suicide-watch.zip to /content\n",
            " 93% 107M/115M [00:01<00:00, 68.9MB/s] \n",
            "100% 115M/115M [00:01<00:00, 82.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zfwtgeva24A",
        "outputId": "843da0a8-81f5-4f6a-d02d-0e6d8805a6c7"
      },
      "source": [
        "!unzip '/content/suicide-watch.zip'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/suicide-watch.zip\n",
            "  inflating: SuicideAndDepression_Detection.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNcPkL4Jauqc"
      },
      "source": [
        "spark_df = spark.read.option(\"header\", \"true\").option(\"multiLine\", \"true\").option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\").option(\"inferSchema\", \"true\").csv('/content/SuicideAndDepression_Detection.csv', sep = ',')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn7LQjkKbBlv",
        "outputId": "a38a827f-76c8-459e-92a8-6a5c77a16d6b"
      },
      "source": [
        "spark_split_df = spark_df.filter(\"class != 'depression'\")\n",
        "\n",
        "(train_data, test_data, val_data) = spark_split_df.randomSplit([0.03, 0.02, 0.9], 24)\n",
        "\n",
        "print(\"Train length\", train_data.count())\n",
        "print(\"Test length\", test_data.count())\n",
        "print(\"validation length\", val_data.count())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train length 7470\n",
            "Test length 4901\n",
            "validation length 219703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrAVvhpwbLES"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.base import *"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbuliup4bajr",
        "outputId": "cc13311a-2f74-4afe-ac17-9dbf357c552f"
      },
      "source": [
        "document = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
        "\n",
        "use = UniversalSentenceEncoder.pretrained() \\\n",
        " .setInputCols([\"document\"])\\\n",
        " .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "# the classes/labels/categories are in category column\n",
        "sentimentdl = ClassifierDLApproach()\\\n",
        "  .setInputCols([\"sentence_embeddings\"])\\\n",
        "  .setOutputCol(\"output\")\\\n",
        "  .setLabelColumn(\"class\")\\\n",
        "  .setMaxEpochs(20)\\\n",
        "  .setEnableOutputLogs(True)\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        use,\n",
        "        sentimentdl\n",
        "    ])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOm3bO2Nbjyh"
      },
      "source": [
        "pipelineModel = pipeline.fit(train_data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoGVEkfNdZSY",
        "outputId": "9693ff6f-f01a-4a74-e75f-ffa5f42fc52c"
      },
      "source": [
        "!cd ~/annotator_logs && ls -l"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "-rw-r--r-- 1 root root 1797 May  8 09:42 ClassifierDLApproach_09856eefc1aa.log\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mO2tbkFW3Cy",
        "outputId": "fdcbb4a3-c4ac-44f2-a949-0fc146e0c73d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!cat ~/annotator_logs/ClassifierDLApproach_09856eefc1aa.log"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training started - total epochs: 20 - learning rate: 0.005 - batch size: 64 - training examples: 7470\n",
            "Epoch 0/20 - 2.781973546%.2fs - loss: 49.50068 - accuracy: 0.9047449 - batches: 117\n",
            "Epoch 1/20 - 2.402888786%.2fs - loss: 46.58053 - accuracy: 0.932276 - batches: 117\n",
            "Epoch 2/20 - 2.443861267%.2fs - loss: 44.75196 - accuracy: 0.9373126 - batches: 117\n",
            "Epoch 3/20 - 2.412652939%.2fs - loss: 44.307034 - accuracy: 0.94256586 - batches: 117\n",
            "Epoch 4/20 - 2.494146079%.2fs - loss: 44.160168 - accuracy: 0.9451251 - batches: 117\n",
            "Epoch 5/20 - 2.9063267%.2fs - loss: 44.207294 - accuracy: 0.9462027 - batches: 117\n",
            "Epoch 6/20 - 2.385497076%.2fs - loss: 44.146 - accuracy: 0.947415 - batches: 117\n",
            "Epoch 7/20 - 2.358323381%.2fs - loss: 43.81656 - accuracy: 0.9484926 - batches: 117\n",
            "Epoch 8/20 - 2.449807016%.2fs - loss: 43.225487 - accuracy: 0.94889665 - batches: 117\n",
            "Epoch 9/20 - 2.383400265%.2fs - loss: 43.59375 - accuracy: 0.948762 - batches: 117\n",
            "Epoch 10/20 - 2.383459633%.2fs - loss: 44.503136 - accuracy: 0.9476844 - batches: 117\n",
            "Epoch 11/20 - 2.34398645%.2fs - loss: 43.80742 - accuracy: 0.9455292 - batches: 117\n",
            "Epoch 12/20 - 2.391267716%.2fs - loss: 43.660614 - accuracy: 0.9470109 - batches: 117\n",
            "Epoch 13/20 - 2.368843547%.2fs - loss: 43.37545 - accuracy: 0.94808847 - batches: 117\n",
            "Epoch 14/20 - 2.381963505%.2fs - loss: 42.66107 - accuracy: 0.94930077 - batches: 117\n",
            "Epoch 15/20 - 2.364126248%.2fs - loss: 42.64691 - accuracy: 0.95037836 - batches: 117\n",
            "Epoch 16/20 - 2.385296665%.2fs - loss: 42.64001 - accuracy: 0.95118654 - batches: 117\n",
            "Epoch 17/20 - 2.34404462%.2fs - loss: 42.60622 - accuracy: 0.95105183 - batches: 117\n",
            "Epoch 18/20 - 2.387695004%.2fs - loss: 42.51865 - accuracy: 0.9519947 - batches: 117\n",
            "Epoch 19/20 - 2.394530662%.2fs - loss: 42.257446 - accuracy: 0.9529376 - batches: 117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O91O9Oqm9W43"
      },
      "source": [
        "df = pipelineModel.transform(test_data)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5DIBLeA-6a2",
        "outputId": "d827faab-2490-430a-8227-c925c9500a5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.show(5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+------------+--------------------+--------------------+--------------------+\n",
            "|                text|       class|            document| sentence_embeddings|              output|\n",
            "+--------------------+------------+--------------------+--------------------+--------------------+\n",
            "|\"Are you afraid t...|   teenagers|[[document, 0, 22...|[[sentence_embedd...|[[category, 0, 22...|\n",
            "|\"Aren't you so gl...|SuicideWatch|[[document, 0, 43...|[[sentence_embedd...|[[category, 0, 43...|\n",
            "|\"Drinking Sprite ...|   teenagers|[[document, 0, 94...|[[sentence_embedd...|[[category, 0, 94...|\n",
            "|\"Friendly\" and ca...|SuicideWatch|[[document, 0, 12...|[[sentence_embedd...|[[category, 0, 12...|\n",
            "|\"I can't breathe....|   teenagers|[[document, 0, 76...|[[sentence_embedd...|[[category, 0, 76...|\n",
            "+--------------------+------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEoRUiMN7w2V",
        "outputId": "b9795b80-071a-4bcd-ff61-62506c2822b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "df = pipelineModel.transform(test_data).select('text', 'class', 'output.result').toPandas()\n",
        "df['result'] = df['result'].apply(lambda x: x[0])\n",
        "print(accuracy_score(df['result'], df['class']))\n",
        "print(classification_report(df['result'], df['class']))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9251173229953071\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "SuicideWatch       0.93      0.92      0.92      2437\n",
            "   teenagers       0.92      0.93      0.93      2464\n",
            "\n",
            "    accuracy                           0.93      4901\n",
            "   macro avg       0.93      0.93      0.93      4901\n",
            "weighted avg       0.93      0.93      0.93      4901\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}