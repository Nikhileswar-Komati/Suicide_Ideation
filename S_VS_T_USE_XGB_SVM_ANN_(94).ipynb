{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "V2_XGB_Deployment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN7nmNJyQAsTXq3UBL4GuRK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhileswar-Komati/Suicide_Ideation/blob/master/S_VS_T_USE_XGB_SVM_ANN_(94).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTlu-l_bdI1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081bbc0d-cdd0-451a-ebf5-fd0993bb75a0"
      },
      "source": [
        "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py\n",
        "!pip install sentencepiece\n",
        "!pip install bert-for-tf2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 4.3MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n",
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/a1/acb891630749c56901e770a34d6bac8a509a367dd74a05daf7306952e910/bert-for-tf2-0.14.9.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.4MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/aa/e0/4f663d8abf83c8084b75b995bd2ab3a9512ebc5b97206fde38cef906ab07/py-params-0.10.2.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-cp37-none-any.whl size=30535 sha256=1776b3404539fdb3afe5b7afa66bb0e2cfe36e981c7816804fb77e0bf47794b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/04/ee/347bd9f5b821b637c76411d280271a857aece00358896a230f\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-cp37-none-any.whl size=7912 sha256=69138135989ea2c2977a484b827f6732668978b9f354878e70fc52e62e89bdcc\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/4a/70/ff12450229ff1955abf01f365051d4faae1c20aef53ab4cf09\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp37-none-any.whl size=19472 sha256=e7bdcae2fa0e0d478afa5eca74675119d99ee6367cb869eaf8b67d604f55561a\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2DwSquv8qSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3622aa9-c9c9-4f25-e19d-c4c5c93acb70"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from xgboost import XGBClassifier\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import os, re\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH98Qwfo8LMj",
        "outputId": "11888d82-7dd2-49c7-9a96-0b22f9f432af"
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"nikhileswarkomati\"\n",
        "os.environ['KAGGLE_KEY'] = \"001b3a30170775e55950edb6ff0c9b17\"\n",
        "!kaggle datasets download -d nikhileswarkomati/suicide-watch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading suicide-watch.zip to /content\n",
            " 84% 97.0M/115M [00:01<00:00, 61.3MB/s]\n",
            "100% 115M/115M [00:01<00:00, 85.3MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AXemEX88XIu",
        "outputId": "8fe624bc-e1e8-447f-f7da-f16ca4093a6c"
      },
      "source": [
        "!unzip '/content/suicide-watch.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/suicide-watch.zip\n",
            "  inflating: SuicideAndDepression_Detection.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "WqC-R1QJ8gKD",
        "outputId": "4eef15a4-5a8e-4569-bbf3-a1a33f1b4edd"
      },
      "source": [
        "data = pd.read_csv('/content/SuicideAndDepression_Detection.csv', lineterminator = '\\n')\n",
        "data.sample(5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50936</th>\n",
              "      <td>byeI don’t belong here. I have no place in thi...</td>\n",
              "      <td>SuicideWatch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200946</th>\n",
              "      <td>2019 will be my last yearI have not decided up...</td>\n",
              "      <td>SuicideWatch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93287</th>\n",
              "      <td>Have you drank water today??? No??? \\n\\n#NOOO?...</td>\n",
              "      <td>teenagers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296671</th>\n",
              "      <td>My family is controlling and unsympathetic I c...</td>\n",
              "      <td>SuicideWatch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83186</th>\n",
              "      <td>I'm telling my parents.I'm 15 and I don't know...</td>\n",
              "      <td>depression</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text         class\n",
              "50936   byeI don’t belong here. I have no place in thi...  SuicideWatch\n",
              "200946  2019 will be my last yearI have not decided up...  SuicideWatch\n",
              "93287   Have you drank water today??? No??? \\n\\n#NOOO?...     teenagers\n",
              "296671  My family is controlling and unsympathetic I c...  SuicideWatch\n",
              "83186   I'm telling my parents.I'm 15 and I don't know...    depression"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4_3TFUs8uA-",
        "outputId": "e4e1924f-a259-42c7-bd7d-aa445be2508b"
      },
      "source": [
        "print(data.shape)\n",
        "data['class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(348111, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "teenagers       116037\n",
              "SuicideWatch    116037\n",
              "depression      116037\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lRhkGN8IE-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ba6d49-e4ee-4983-b771-d2acf1abd80c"
      },
      "source": [
        "def preprocess(string):\n",
        "    phrase = str(string)\n",
        "    phrase = re.sub('[^a-z]+', ' ', phrase, flags = re.IGNORECASE)\n",
        "    phrase = re.sub('(\\s+)', ' ', phrase)\n",
        "    phrase = re.sub('http\\S+', ' ', phrase)\n",
        "    phrase = phrase.lower()\n",
        "    words_li = ['filler']\n",
        "    li = list(stopwords.words()) + words_li\n",
        "    text_tokens = word_tokenize(phrase)\n",
        "    return \" \".join([word for word in text_tokens if word not in li])\n",
        "print(data['text'].apply(lambda x: len(x.split(' '))).sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59527144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKPzRpE5JzQQ"
      },
      "source": [
        "data['text'] = data['text'].map(lambda string: preprocess(string))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaDIwATpsLRU",
        "outputId": "aa5cb450-58b1-49e2-cf14-52ecfb3020fd"
      },
      "source": [
        "print(data['text'].apply(lambda x: len(x.split(' '))).sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "59527144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVEHdqxP671Q",
        "outputId": "a12cd66e-0c72-4424-8d2a-4dfbc89bb336"
      },
      "source": [
        "data.loc[(data['class'] != 'depression'), 'text'][:1000].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txfNhIm4-LEK",
        "outputId": "8f5b0440-0c4e-4c12-8117-dddca129aa44"
      },
      "source": [
        "# X = data.iloc[:, 0].values\n",
        "# y = data.iloc[:, 1].values\n",
        "\n",
        "# le = LabelEncoder()\n",
        "\n",
        "# y = le.fit_transform(y)\n",
        "\n",
        "# train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = 0.5, stratify = y)\n",
        "# train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, train_size = 0.2, stratify = train_y)\n",
        "# print(train_X.shape, test_y.shape, val_X.shape)\n",
        "\n",
        "#------------------------------------------------------------------------------------------\n",
        "X = data.loc[(data['class'] != 'depression'), 'text'].values\n",
        "y = data.loc[(data['class'] != 'depression'), 'class'].values\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, train_size = 0.5, stratify = y)\n",
        "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, train_size = 0.2, stratify = train_y)\n",
        "print(train_X.shape, test_y.shape, val_X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23207,) (116037,) (92830,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk1UEAHi8mHd"
      },
      "source": [
        "[preproele for ele in data.loc[(data['class'] != 'depression'), 'text'][:10000].values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4zppob4oOwy"
      },
      "source": [
        "embeddings = embed(data.loc[(data['class'] != 'depression'), 'text'][:10000].values)\n",
        "train_y = le.fit_transform(data.loc[(data['class'] != 'depression'), 'class'][:10000].values)\n",
        "test_embeddings = embed(data.loc[(data['class'] != 'depression'), 'text'][10000:15000].values)\n",
        "test_y = le.transform(data.loc[(data['class'] != 'depression'), 'class'][10000:15000].values)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------------\n",
        "# embeddings = embed([preprocess(ele) for ele in data.loc[(data['class'] != 'depression'), 'text'][:10000].values])\n",
        "# train_y = le.fit_transform(data.loc[(data['class'] != 'depression'), 'class'][:10000].values)\n",
        "# test_embeddings = embed([preprocess(ele) for ele in data.loc[(data['class'] != 'depression'), 'text'][10000:15000].values])\n",
        "# test_y = le.transform(data.loc[(data['class'] != 'depression'), 'class'][10000:15000].values)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLu8Jn9srZ2f",
        "outputId": "6d748266-4fc6-44fb-d0f0-a9f5b575dba5"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "\n",
        "\n",
        "sgd = SGDClassifier()\n",
        "\n",
        "sgd.fit(embeddings, train_y)\n",
        "print(\"---------TRAINING_________DONE--------------\")\n",
        "\n",
        "y_pred = sgd.predict(test_embeddings)\n",
        "print(accuracy_score(y_pred, test_y))\n",
        "print(classification_report(test_y, y_pred))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------TRAINING_________DONE--------------\n",
            "0.9404\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94      2512\n",
            "           1       0.95      0.93      0.94      2488\n",
            "\n",
            "    accuracy                           0.94      5000\n",
            "   macro avg       0.94      0.94      0.94      5000\n",
            "weighted avg       0.94      0.94      0.94      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c44n7y0jqoVP",
        "outputId": "33dcf942-af33-4961-cd83-a000c1f62ca7"
      },
      "source": [
        "\n",
        "\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "xgb.fit(embeddings, train_y)\n",
        "print(\"---------TRAINING_________DONE--------------\")\n",
        "\n",
        "y_pred = xgb.predict(test_embeddings)\n",
        "print(accuracy_score(y_pred, test_y))\n",
        "print(classification_report(test_y, y_pred))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------TRAINING_________DONE--------------\n",
            "0.9334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.93      2512\n",
            "           1       0.93      0.94      0.93      2488\n",
            "\n",
            "    accuracy                           0.93      5000\n",
            "   macro avg       0.93      0.93      0.93      5000\n",
            "weighted avg       0.93      0.93      0.93      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tk3Vx-avQm2",
        "outputId": "7b887823-ac6a-455f-c3d2-35e5a12a36bf"
      },
      "source": [
        "xgb1 = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', XGBClassifier()),\n",
        "              ])\n",
        "\n",
        "xgb1.fit(train_X, train_y)\n",
        "y_pred = xgb1.predict(test_X)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, test_y))\n",
        "print(classification_report(test_y, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.8860622042969053\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.84      0.88     58019\n",
            "           1       0.86      0.93      0.89     58018\n",
            "\n",
            "    accuracy                           0.89    116037\n",
            "   macro avg       0.89      0.89      0.89    116037\n",
            "weighted avg       0.89      0.89      0.89    116037\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbRXcqp_H90R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b334a9-5fdf-42c6-9d5d-51669f82b060"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd2 = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', SGDClassifier()),\n",
        "              ])\n",
        "\n",
        "sgd2.fit(train_X, train_y)\n",
        "y_pred = sgd2.predict(test_X)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, test_y))\n",
        "print(classification_report(test_y, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 0.9283073502417333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.92      0.93     58019\n",
            "           1       0.92      0.94      0.93     58018\n",
            "\n",
            "    accuracy                           0.93    116037\n",
            "   macro avg       0.93      0.93      0.93    116037\n",
            "weighted avg       0.93      0.93      0.93    116037\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq-5y0xr_7OM",
        "outputId": "55f39b59-bab2-4e96-f7f9-d276fea580da"
      },
      "source": [
        "import itertools\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Embedding\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import utils\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
        "\n",
        "# max_words = 750\n",
        "# tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
        "# tokenize.fit_on_texts(train_X) # only fit on train\n",
        "\n",
        "# x_train = tokenize.texts_to_matrix(train_X)\n",
        "# x_test = tokenize.texts_to_matrix(test_X)\n",
        "\n",
        "num_classes = 2\n",
        "y_train = utils.to_categorical(train_y, num_classes)\n",
        "y_test = utils.to_categorical(test_y, num_classes)\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(512,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "history = model.fit(embeddings, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=20,\n",
        "                    verbose=1,\n",
        "                    callbacks = [checkpoint, earlystopping],\n",
        "                    validation_split=0.1)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "282/282 [==============================] - 2s 6ms/step - loss: 0.3353 - accuracy: 0.8916 - val_loss: 0.1788 - val_accuracy: 0.9410\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.94100, saving model to model.h5\n",
            "Epoch 2/20\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1777 - accuracy: 0.9330 - val_loss: 0.1724 - val_accuracy: 0.9430\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.94100 to 0.94300, saving model to model.h5\n",
            "Epoch 3/20\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1616 - accuracy: 0.9403 - val_loss: 0.1706 - val_accuracy: 0.9420\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.94300\n",
            "Epoch 4/20\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1512 - accuracy: 0.9434 - val_loss: 0.1664 - val_accuracy: 0.9440\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.94300 to 0.94400, saving model to model.h5\n",
            "Epoch 5/20\n",
            "282/282 [==============================] - 2s 5ms/step - loss: 0.1389 - accuracy: 0.9515 - val_loss: 0.1654 - val_accuracy: 0.9450\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.94400 to 0.94500, saving model to model.h5\n",
            "Epoch 6/20\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1465 - accuracy: 0.9461 - val_loss: 0.1630 - val_accuracy: 0.9430\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.94500\n",
            "Epoch 7/20\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1211 - accuracy: 0.9554 - val_loss: 0.1576 - val_accuracy: 0.9440\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.94500\n",
            "Epoch 8/20\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1187 - accuracy: 0.9586 - val_loss: 0.1565 - val_accuracy: 0.9450\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.94500\n",
            "Epoch 9/20\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1095 - accuracy: 0.9632 - val_loss: 0.1660 - val_accuracy: 0.9450\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.94500\n",
            "Epoch 10/20\n",
            "282/282 [==============================] - 1s 5ms/step - loss: 0.1015 - accuracy: 0.9656 - val_loss: 0.1616 - val_accuracy: 0.9440\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.94500\n",
            "Epoch 00010: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO4r8J6eUaGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de7dbe66-4c2f-494f-d436-36773d3e82a0"
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/model.h5')\n",
        "y_pred = model.predict(test_embeddings)\n",
        "y_pred = np.argmax(y_pred, axis = 1)\n",
        "y_test = np.argmax(y_test, axis = 1)\n",
        "print(accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_pred, y_test))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9416\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.94      2492\n",
            "           1       0.95      0.94      0.94      2508\n",
            "\n",
            "    accuracy                           0.94      5000\n",
            "   macro avg       0.94      0.94      0.94      5000\n",
            "weighted avg       0.94      0.94      0.94      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}