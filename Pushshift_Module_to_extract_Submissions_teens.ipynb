{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pushshift Module to extract Submissions.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhileswar-Komati/Suicide_Ideation/blob/master/Pushshift_Module_to_extract_Submissions_teens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyarnetivJPG"
      },
      "source": [
        "# Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfmIce345UaB"
      },
      "source": [
        "import pandas as pd\n",
        "import requests #Pushshift accesses Reddit via an url so this is needed\n",
        "import json #JSON manipulation\n",
        "import csv #To Convert final table into a csv file to save to your machine\n",
        "import time\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj8JGor4vMwC"
      },
      "source": [
        "# Pushshift URL Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH8nB39CzZfU"
      },
      "source": [
        "#We can access the Pushshift API through building an URL with the relevant parameters without even needing Reddit credentials.\n",
        "#These are some examples. You can follow the links and they will generate a page with JSON data\n",
        "test_url = \"https://api.pushshift.io/reddit/search/submission/?&after=1609505059&before=1609520400&subreddit=SuicideWatch\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1_QI6ObRbLt"
      },
      "source": [
        "data = getPushshiftData(1268811603, 1609520400, 'SuicideWatch')\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDma-H_k0frf"
      },
      "source": [
        "#Adapted from this https://gist.github.com/dylankilkenny/3dbf6123527260165f8c5c3bc3ee331b\n",
        "#This function builds an Pushshift URL, accesses the webpage and stores JSON data in a nested list\n",
        "def getPushshiftData(after, before, sub):\n",
        "    #Build URL\n",
        "    url = 'https://api.pushshift.io/reddit/search/submission/?&size=1000&after='+str(after)+'&before='+str(before)+'&subreddit='+str(sub)\n",
        "    #Print URL to show user\n",
        "    print(url)\n",
        "    #Request URL\n",
        "    r = requests.get(url)\n",
        "    #Load JSON data from webpage into data variable\n",
        "    data = json.loads(r.text)\n",
        "    #return the data element which contains all the submissions data\n",
        "    # print(\"No Error\")\n",
        "    return data['data']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6qX7glQ1-nl"
      },
      "source": [
        "#This function will be used to extract the key data points from each JSON result\n",
        "def collectSubData(subm):\n",
        "    #subData was created at the start to hold all the data which is then added to our global subStats dictionary.\n",
        "    subData = list() #list to store data points\n",
        "    title = subm['title']\n",
        "    sub_id = subm['id']\n",
        "    score = subm['score']\n",
        "    created = datetime.datetime.fromtimestamp(subm['created_utc']) #1520561700.0\n",
        "    numComms = subm['num_comments']\n",
        "    selftext = subm['selftext']\n",
        "    subreddit = subm['subreddit']\n",
        "    over_18 = subm['over_18']\n",
        "    #Put all data points into a tuple and append to subData\n",
        "    subData.append((sub_id,title,selftext,score,created,numComms,over_18,subreddit))\n",
        "    #Create a dictionary entry of current submission data and store all data related to it\n",
        "    subStats[sub_id] = subData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCDRrn9nwRsj"
      },
      "source": [
        "# Update your Search Settings here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0fNU7eS2mwT"
      },
      "source": [
        "#Create your timestamps and queries for your search URL\n",
        "#https://www.unixtimestamp.com/index.php > Use this to create your timestamps\n",
        "after = \"1230768000\" #Submissions after this timestamp (1577836800 = 01 Jan 20)1229385600\n",
        "before = \"1609520400\" #Submissions before this timestamp (1607040000 = 04 Dec 20)\n",
        "#Keyword(s) to look for in submissions\n",
        "sub = \"depression\" #Which Subreddit to search in\n",
        "\n",
        "#subCount tracks the no. of total submissions we collect\n",
        "subCount = 0\n",
        "#subStats is the dictionary where we will store our data.\n",
        "subStats = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wP_j8pp2-M8"
      },
      "source": [
        "# We need to run this function outside the loop first to get the updated after variable\n",
        "data = getPushshiftData(after, before, sub)\n",
        "# Will run until all posts have been gathered i.e. When the length of data variable = 0\n",
        "# from the 'after' date up until before date\n",
        "while len(data) > 0: #The length of data is the number submissions (data[0], data[1] etc), once it hits zero (after and before vars are the same) end\n",
        "    for submission in data:\n",
        "        try:\n",
        "          collectSubData(submission)\n",
        "          subCount+=1\n",
        "        except:\n",
        "          continue\n",
        "    # Calls getPushshiftData() with the created date of the last submission\n",
        "    # print(len(data))\n",
        "    # print(str(datetime.datetime.fromtimestamp(data[-1]['created_utc'])))\n",
        "    #update after variable to last created date of submission\n",
        "    after = data[-1]['created_utc']\n",
        "    # print(\"CHECK\")\n",
        "    #data has changed due to the new after variable provided by above code\n",
        "    try:\n",
        "      data = getPushshiftData(after, before, sub)\n",
        "      print(subCount)\n",
        "    except:\n",
        "      while 1:\n",
        "        if int(after) >= int(before):\n",
        "          break\n",
        "        try:\n",
        "          print(str(datetime.datetime.fromtimestamp(data[-1]['created_utc'])))\n",
        "          after += 10000000\n",
        "          data = getPushshiftData(after, before, sub)\n",
        "          print(subCount)\n",
        "          break\n",
        "        except:\n",
        "          after += 10000000\n",
        "\n",
        "print(len(data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaeTGu7mwyoU"
      },
      "source": [
        "# Check your Submission Extraction was successful"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVLuSJ8e8p7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9bdc612-6b95-4725-974a-a4892da984dc"
      },
      "source": [
        "print(str(len(subStats)) + \" submissions have added to list\")\n",
        "print(\"1st entry is:\")\n",
        "print(list(subStats.values())[0][0][1] + \" created: \" + str(list(subStats.values())[0][0][5]))\n",
        "print(\"Last entry is:\")\n",
        "print(list(subStats.values())[-1][0][1] + \" created: \" + str(list(subStats.values())[-1][0][5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78889 submissions have added to list\n",
            "1st entry is:\n",
            "Girls, the future and some other stuff. created: 0\n",
            "Last entry is:\n",
            "I am trying so hard but things just keep getting worse created: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAm_zZZfw521"
      },
      "source": [
        "# Save data to CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBikywNJ8ufl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0beafc99-42ec-49bf-fc59-86b826a0304c"
      },
      "source": [
        "def updateSubs_file():\n",
        "    upload_count = 0\n",
        "    #location = \"\\\\Reddit Data\\\\\" >> If you're running this outside of a notebook you'll need this to direct to a specific location\n",
        "    print(\"input filename of submission file, please add .csv\")\n",
        "    filename = input() #This asks the user what to name the file\n",
        "    file = filename\n",
        "    with open(file, 'w', newline='', encoding='utf-8') as file: \n",
        "        a = csv.writer(file, delimiter=',')\n",
        "        headers = [\"Post_iD\",\"Title\",\"Body\",\"Score\",\"Publish_date\",\"Total_no_of_comments\", \"Over_18\", \"Subreddit\"]\n",
        "        a.writerow(headers)\n",
        "        for sub in subStats:\n",
        "            a.writerow(subStats[sub][0])\n",
        "            upload_count+=1\n",
        "            \n",
        "        print(str(upload_count) + \" submissions have been uploaded\")\n",
        "updateSubs_file()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input filename of submission file, please add .csv\n",
            "pushshift_dep.csv\n",
            "78889 submissions have been uploaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFGb6F-WfBU1",
        "outputId": "9c354ef1-6079-4a5e-8734-de70a4503a01"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/pushshiftmax.csv')\n",
        "df1 = pd.read_csv('/content/pushshiftmax1.csv')\n",
        "df2 = pd.read_csv('/content/pushshiftmax2.csv')\n",
        "df3 = pd.read_csv('/content/pushshiftmax3.csv')\n",
        "\n",
        "data = pd.concat([df, df1, df2, df3])\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50886, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7_if62Nk2rh",
        "outputId": "0ac73fd6-3e8b-4548-b0d0-99380b7105b1"
      },
      "source": [
        "df1 = pd.read_csv('/content/pushshift_dep.csv')\n",
        "df2 = pd.read_csv('/content/pushshift_sw.csv')\n",
        "\n",
        "data = pd.concat([df1, df2])\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129776, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhh0gReVlFUz"
      },
      "source": [
        "data.to_csv('PushShift_129776.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8eR_IZjlQVn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}